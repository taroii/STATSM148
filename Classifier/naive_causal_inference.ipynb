{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('smaller_sample.csv')\n",
    "events = pd.read_csv('event_definitions.csv')\n",
    "# df = df.drop(columns=['order_ships', 'first_3_events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(og_df, defs):\n",
    "    df = og_df[['customer_id',\n",
    "             'account_id',\n",
    "             'ed_id',\n",
    "             'event_name',\n",
    "             'event_timestamp',\n",
    "             'journey_steps_until_end',\n",
    "             'milestone_number',\n",
    "             'journey_id',]]\n",
    "    \n",
    "    df.loc[:,['milestone_number']] = df['milestone_number'].copy().fillna(0)\n",
    "\n",
    "    df = df.drop_duplicates(subset=['customer_id', 'account_id', 'ed_id', 'event_name', 'event_timestamp'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    j_steps = df['journey_steps_until_end']\n",
    "    s_corrected = correct_sequences(j_steps)\n",
    "    df['journey_steps_until_end'] = s_corrected\n",
    "\n",
    "    df['event_timestamp'] = pd.to_datetime(df['event_timestamp'])\n",
    "    df_stages = defs[['event_name', 'stage']]\n",
    "    \n",
    "    df = pd.merge(df, df_stages, on ='event_name', how = 'left')\n",
    "    \n",
    "    df['account_id'] = remove_if(df, 'account_id')\n",
    "\n",
    "    df['customer_id'] = remove_if(df, 'customer_id')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_time_since_last_event(cust_df, n=10):\n",
    "    cust_df = cust_df.head(n)\n",
    "    x = cust_df.groupby(['customer_id', 'journey_id'])['event_timestamp'].diff()\n",
    "    x = x.fillna(pd.Timedelta(seconds=0))\n",
    "    x = x.dt.total_seconds()\n",
    "    x = x.tolist() + [0] * (n - len(x))\n",
    "    return np.array(x)\n",
    "\n",
    "\n",
    "def classification_dataset(data, event_defs, n_events = 10):\n",
    "    df = data_cleaner(data, event_defs)\n",
    "\n",
    "    idxs = list(df[df['event_name'] == 'promotion_created'].index)\n",
    "    df.drop(idxs, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    new_df = df.groupby('customer_id').apply(group_by_approach)\n",
    "    new_df.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "    x = list(df.groupby('customer_id').apply(get_first_n_events, n = n_events))\n",
    "    new_df['first_' + str(n_events) + '_events'] = x\n",
    "    \n",
    "    # x = list(df.groupby('customer_id').apply(get_time_since_last_event, n = n_events))\n",
    "    # new_df['time_since_last_event'] = x\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_events_fixed = 15\n",
    "col_name = 'first_' + str(number_events_fixed) +'_events'\n",
    "\n",
    "df = classification_dataset(data, events, n_events=number_events_fixed)\n",
    "df.reindex(sorted(df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_ids = df.index\n",
    "cust_ids = [x[0] for x in cust_ids]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['customer_id'] = cust_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_journeys', 'max_journey', 'discover', 'number_accounts',\n",
       "       'one_more_journey', 'most_repeated_event', 'average_length_seq',\n",
       "       'approved_credit', 'first_purchase', 'account_activitation',\n",
       "       'downpayment_received', 'downpayment_cleared', 'order_ships',\n",
       "       'max_milestone', 'has_prospecting', 'has_pre_application',\n",
       "       'initial_device', 'time_in_discover', 'time_in_apply',\n",
       "       'first_15_events', 'customer_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly examines \"downpayment received\" since this leads to orders being shipped\n",
    "# dropping some columns\n",
    "\n",
    "df = df.drop(columns=['order_ships', 'max_milestone', 'downpayment_cleared', 'first_purchase', 'customer_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='first_15_events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change time to hours to prevent large numbers\n",
    "df.time_in_apply = df.time_in_apply / 3600\n",
    "df.time_in_discover = df.time_in_discover / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Causal ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect: -0.00108 \n",
      " Lower Bound: -0.00403, Upper Bound: 0.00188\n"
     ]
    }
   ],
   "source": [
    "from causalml.inference.meta import LRSRegressor, MLPTRegressor, XGBTRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDRegressor, ElasticNet, LogisticRegression\n",
    "\n",
    "df = df[~df.initial_device.isna()]\n",
    "X = df.drop(columns=['discover', 'downpayment_received'])\n",
    "target = df.downpayment_received.astype(int)\n",
    "treatment = df.discover.astype(int)\n",
    "\n",
    "nn_regressor = MLPTRegressor(hidden_layer_sizes=(50, 50),\n",
    "                             learning_rate_init=.05,\n",
    "                             early_stopping=True,\n",
    "                             random_state=2024)\n",
    "treatment_effects, lower_bound, upper_bound = nn_regressor.estimate_ate(X=X, treatment=treatment, y=target)\n",
    "print(f'Average Treatment Effect: {treatment_effects[0]:.5f} \\n Lower Bound: {lower_bound[0]:.5f}, Upper Bound: {upper_bound[0]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect: -0.03264 \n",
      " Lower Bound: -0.03496, Upper Bound: -0.03032\n"
     ]
    }
   ],
   "source": [
    "xgb_regressor = XGBTRegressor(random_state=2024)\n",
    "treatment_effects, lower_bound, upper_bound = xgb_regressor.estimate_ate(X=X, treatment=treatment, y=target)\n",
    "print(f'Average Treatment Effect: {treatment_effects[0]:.5f} \\n Lower Bound: {lower_bound[0]:.5f}, Upper Bound: {upper_bound[0]:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued: some other regressors and placebo test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dowhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import CausalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a naive causal graph, can add more in the future\n",
    "\n",
    "'''\n",
    "graph = nx.DiGraph([('discover', 'first_purchase'), ('first_purchase', 'account_activation'), ('account_activation', 'downpayment_received'), ('downpayment_received', 'downpayment_cleared'), ('downpayment_cleared', 'order_shipped')])\n",
    "graph_gml = ''.join(nx.generate_gml(graph))\n",
    "'''\n",
    "\n",
    "model = CausalModel(\n",
    "    data=df,\n",
    "    treatment='discover',\n",
    "    outcome='order_shipped',\n",
    "    common_causes=['num_journeys', 'max_journey', 'max_milestone', 'number_accounts', 'one_more_journey', 'most_repeated_event', 'average_length_seq'],\n",
    "    effect_modifiers=['first_purchase', 'account_activation', 'downpayment_received', 'downpayment_cleared']\n",
    "    # graph=graph_gml\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_regression\n",
      "{'control_value': 0, 'treatment_value': 1, 'test_significance': None, 'evaluate_effect_strength': False, 'confidence_intervals': False, 'target_units': 'ate', 'effect_modifiers': ['first_purchase', 'account_activation', 'downpayment_received', 'downpayment_cleared']}\n"
     ]
    }
   ],
   "source": [
    "estimate = model.estimate_effect(identified_estimand=identified_estimand, method_name='backdoor.linear_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing the treatment variable(s) [discover] from 0 to 1 causes an increase of -0.0003121286570691717 in the expected value of the outcome [order_shipped], over the data distribution/population represented by the dataset.\n"
     ]
    }
   ],
   "source": [
    "estimate.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_value': array([4.899196e-10])}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate.test_stat_significance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate.get_confidence_intervals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(âˆ’0.00152676624930032, 0.00114034686083087)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refute_res = model.refute_estimate(estimand=identified_estimand, estimate=estimate, method_name='random_common_cause', show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refute: Add a random common cause\n",
      "Estimated effect:-0.0003121286570691717\n",
      "New effect:-0.00031223762868127223\n",
      "p value:0.8999999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(refute_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P value for refute_res > 0.05, meaning that linear regression is reasonably robust to refutation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
