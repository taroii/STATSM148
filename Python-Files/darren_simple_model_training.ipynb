{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('smaller_sample.csv')\n",
    "events = pd.read_csv('Event Definitions.csv')\n",
    "# data.customer_id = list(range(0, len(data)))\n",
    "df = fingerhut_data_cleaner(data, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(df[df['event_name'] == 'promotion_created'].index)\n",
    "df.drop(idxs, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_downpayment_cleared(df):\n",
    "    downpaymen_cleared = df.groupby('customer_id')['ed_id'].apply(lambda x: 27 in x.values).reset_index(name='downpayment_cleared')\n",
    "    return pd.merge(df, downpaymen_cleared, on='customer_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some other features. Will need more in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_n_accounts(df)\n",
    "df = add_has_discover(df)\n",
    "df = add_downpayment_cleared(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter customers with at least 10 events and downpayment not cleared in the first 10 events. Want to see if models can predict whether or not a customer clears downpayment by only looking at first 10 actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\n",
    "        ['customer_id', 'journey_steps_until_end']\n",
    "    ).groupby(['customer_id'], sort=False).agg(\n",
    "        {\n",
    "            'ed_id': lambda x: list(x)[:10],\n",
    "            'journey_steps_until_end': lambda x: list(x)[-1],\n",
    "            'has_discover': 'first',\n",
    "            'downpayment_cleared': 'first',\n",
    "            'n_accounts': 'first',\n",
    "        }\n",
    ")\n",
    "\n",
    "df = df[df.ed_id.apply(lambda x: len(x) == 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df[df.ed_id.apply(lambda x: 27 in x)].index\n",
    "df.drop(idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.drop(columns=['downpayment_cleared', 'customer_id'])\n",
    "target = df.downpayment_cleared.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, embedding_dim, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed event id sequence into smaller dimension\n",
    "event_id = df_X.ed_id\n",
    "event_id = torch.tensor(event_id.to_list()).float()\n",
    "emb = Embedding(5)\n",
    "event_id = emb(event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression / Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id_df = pd.DataFrame(event_id.detach().numpy())\n",
    "ori_dfx = df_X.drop(columns='ed_id').reset_index(drop=True)\n",
    "new_dfx = pd.concat([ori_dfx, event_id_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_dfx, target, train_size=.8, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7217759731662106"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_train, y_train)\n",
    "prediction = log_clf.predict(X_test)\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7234530850030895"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(n_estimators=200, \n",
    "                    max_depth=10, \n",
    "                    learning_rate=0.1, \n",
    "                    tree_method='approx',\n",
    "                    objective='binary:logistic')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensors = [torch.tensor(df[feature].values).float().unsqueeze(1) for \\\n",
    "                   feature in ['journey_steps_until_end', 'has_discover', 'n_accounts']]\n",
    "\n",
    "res = torch.cat([event_id] + feature_tensors, dim=1).to(device)\n",
    "target = torch.tensor(target, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(res, target, train_size=.8, random_state=42)\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10, Loss: 0.3899, Validation Loss: 0.5520, Accuracy: 72.6807\n",
      "Epoch 2 / 10, Loss: 0.5274, Validation Loss: 0.5716, Accuracy: 70.3063\n",
      "Epoch 3 / 10, Loss: 0.1835, Validation Loss: 0.5574, Accuracy: 72.6631\n",
      "Epoch 4 / 10, Loss: 0.4919, Validation Loss: 0.5472, Accuracy: 72.5925\n",
      "Epoch 5 / 10, Loss: 0.8179, Validation Loss: 0.5706, Accuracy: 72.6807\n",
      "Epoch 6 / 10, Loss: 0.6930, Validation Loss: 0.5803, Accuracy: 68.7792\n",
      "Epoch 7 / 10, Loss: 0.6653, Validation Loss: 0.5925, Accuracy: 69.0794\n",
      "Epoch 8 / 10, Loss: 0.5114, Validation Loss: 0.5547, Accuracy: 71.3126\n",
      "Epoch 9 / 10, Loss: 0.2207, Validation Loss: 0.5662, Accuracy: 72.6631\n",
      "Epoch 10 / 10, Loss: 0.3752, Validation Loss: 0.5426, Accuracy: 72.6013\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(1)\n",
    "model = Classifier(input_dim=8).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs.detach_()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            prediction = (outputs > 0.5).float()\n",
    "            correct += (prediction == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "    val_loss /= len(test_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} / {num_epochs}, Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {float(correct) / float(total) * 100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
